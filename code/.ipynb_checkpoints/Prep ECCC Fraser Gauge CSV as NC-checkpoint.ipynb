{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-2-bccf2ee1c521>, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-bccf2ee1c521>\"\u001b[1;36m, line \u001b[1;32m33\u001b[0m\n\u001b[1;33m    ' to extract specific rows\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Created Apr 2021 by GO                                                     \"\"\"\n",
    "\"\"\" Write ECCC CSV gauge data to NetCDF                                        \"\"\"\n",
    "\"\"\" Code derived from functions in:                                            \"\"\"\n",
    "\"\"\"     https://gitlab.com/FA12/datatools/-/blob/master/datatools/datatools.py \"\"\"\n",
    "\"\"\" Converter helpers. Used to convert various data formats to nc files.       \"\"\"\n",
    "\"\"\" To do (Apr 12): replace hard-coding of rows extracted                      \"\"\"\n",
    "\"\"\" \"\"\"\n",
    "\n",
    "import csv\n",
    "import datetime as dt\n",
    "import glob\n",
    "import os\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import yaml\n",
    "\n",
    "def read_hist_hydro(file):\n",
    "    \"\"\" Load fraser discharge data received from ECCC open, historical data portal\n",
    "    https://wateroffice.ec.gc.ca/search/historical_e.html\n",
    "\n",
    "    Columns:\n",
    "    station, param, date, value, SYM\n",
    "    daily discharge param = 1\n",
    "    1980-01-01 = row 24779 (zero indexed)\n",
    "    2019-12-31 = row 39388\n",
    "    data += cdata[24779:39388]\n",
    "    \"\"\"\n",
    "    data = []\n",
    "  \n",
    "    with open(file) as f:\n",
    "        fiter = csv.reader(f)\n",
    "        cdata = [d for d in fiter]\n",
    "    data += cdata[2:]\n",
    "        \n",
    "    # convert date\n",
    "    tt = parse_time([d[2] for d in data])\n",
    "    \n",
    "    # convert data\n",
    "    ff = np.array([float(x[3]) for x in data])\n",
    "    return tt, ff\n",
    "\n",
    "def parse_time(t):\n",
    "    \"\"\" Convert time strings to datetime\n",
    "\n",
    "    Can process strings in the following formats:\n",
    "    2012-01-04 19:10\n",
    "    2012-01-04 19:10:00\n",
    "    2012-01-04 19:10:00+00:00\n",
    "    2019-05-24 23:13:41.500000+00:00  # 6 decimal places for seconds\n",
    "    with any delimiters between numbers and + or - before the offset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : list/iterable of strings\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np array of datetime objects\n",
    "    \"\"\"\n",
    "    offset_index = 19\n",
    "    #   strptime is slow, faster version follows\n",
    "    #   tt = [dt.datetime.strptime(x[:19], '%Y-%m-%d %H:%M:%S') for x in t]\n",
    "    y = [int(x[0:4]) for x in t]\n",
    "    m = [int(x[5:7]) for x in t]\n",
    "    d = [int(x[8:10]) for x in t]\n",
    "    H = [12 for x in t]\n",
    "    M = [0 for x in t]\n",
    "    \n",
    "    if len(t[0]) > 16:  # seconds are present\n",
    "        S = [int(x[17:19]) for x in t]\n",
    "    else:  # no seconds\n",
    "        S = [0] * len(y)\n",
    "    if len(t[0]) > 19 and t[0][19] == '.':  # microseconds are present; must be 6 digits\n",
    "        offset_index += 7\n",
    "        MS = [int(x[20:26]) for x in t]\n",
    "    else:\n",
    "        MS = [0] * len(y)\n",
    "\n",
    "    tt = np.array([dt.datetime(*x) for x in zip(y, m, d, H, M, S, MS)])\n",
    "\n",
    "    if len(t[0]) > offset_index and t[0][offset_index] in '+-':  # offset is present\n",
    "        osgn = [int(x[offset_index] + '1') for x in t]  # offset sign\n",
    "        ioh0 = offset_index + 1\n",
    "        ioh1 = offset_index + 3\n",
    "        iom0 = offset_index + 4\n",
    "        iom1 = offset_index + 6\n",
    "        oh = [int(x[ioh0:ioh1]) for x in t]  # offset hour\n",
    "        om = [int(x[iom0:iom1]) for x in t]  # offset minute\n",
    "        # time offset\n",
    "        to = np.array([dt.timedelta(hours=sign * hhh, minutes=sign * mmm)\n",
    "                       for sign, hhh, mmm in zip(osgn, oh, om)])\n",
    "        tt -= to  # https://en.wikipedia.org/wiki/ISO_8601#Time_offsets_from_UTC\n",
    "\n",
    "    return tt\n",
    "\n",
    "def write_netcdf(fname, date, waterlevel=None, discharge=None, temperature=None, pressure=None):\n",
    "    \"\"\" Write/append specified variables to nc file. \"\"\"\n",
    "\n",
    "    var_names = ['waterlevel', 'discharge', 'temperature', 'pressure']\n",
    "    var_units = [\"m\", \"m^3 s-1\", \"Celcius\", \"Pa\"]\n",
    "    var_values = [waterlevel, discharge, temperature, pressure]\n",
    "\n",
    "    # append if file exists, otherwise write a new file\n",
    "    with nc.Dataset(fname, 'a' if os.path.isfile(fname) else 'w') as ncf:\n",
    "        # dimensions\n",
    "        if 'time_counter' not in ncf.dimensions:\n",
    "            ncf.createDimension(\"time_counter\", None)\n",
    "\n",
    "        # time vector\n",
    "        if 'time_counter' not in ncf.variables:\n",
    "            time_counter = ncf.createVariable(\"time_counter\", \"double\", \"time_counter\", zlib=True, fill_value=0.0)\n",
    "            time_counter.standard_name = \"time\"\n",
    "            time_counter.units = \"seconds since 1950-01-01 00:00:00\"\n",
    "            time_counter.calendar = \"gregorian\"\n",
    "        else:\n",
    "            time_counter = ncf.variables['time_counter']\n",
    "        sz = time_counter.size\n",
    "        time_index = slice(sz, sz + len(date))  # at which indices to write the new data\n",
    "        time_counter[time_index] = nc.date2num(date, time_counter.units, time_counter.calendar)\n",
    "\n",
    "        # variables\n",
    "        for vname, units, vals in zip(var_names, var_units, var_values):\n",
    "            if vals is not None:\n",
    "                if vname not in ncf.variables:\n",
    "                    var = ncf.createVariable(vname, \"float32\", \"time_counter\", zlib=True, fill_value=0.0)\n",
    "                    var.units = units\n",
    "                ncf.variables[vname][time_index] = vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates, values = read_hist_hydro('..//data//runoff//gauge//BC_08MF005_Daily_1979_to_2021.csv')\n",
    "write_netcdf(\"BC_08MF005_1979_to_2019.nc\", dates, discharge=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 861.,  847.,  826., ..., 1130., 1120., 1130.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
